{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering Task 1:**"
      ],
      "metadata": {
        "id": "A778DI6lRT9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from a CSV file\n",
        "data = pd.read_csv(\"start.csv\")\n",
        "\n",
        "# Iterate through each column\n",
        "for column in data.columns:\n",
        "    # Check if the column has any missing or zero values\n",
        "    if data[column].isna().sum() + (data[column] == 0).sum() > 0:\n",
        "        # Check if the column is categorical\n",
        "        if data[column].dtype == 'object':\n",
        "            # Impute missing and zero values with the most frequent value\n",
        "            mode_value = data[column].mode()[0]\n",
        "            data[column].fillna(mode_value, inplace=True)\n",
        "            data[column] = data[column].replace(0, mode_value)\n",
        "           # print(\"Column '{}' has been updated. Missing or zero values before: {}. Missing or zero values after: {}. Imputed with value: {}\".format(column, data[column].isna().sum() + (data[column] == 0).sum(), data[column].isna().sum() + (data[column] == 0).sum(), mode_value))\n",
        "        # Otherwise, assume it's a continuous numerical value\n",
        "        else:\n",
        "            # Impute missing and zero values with the mean value\n",
        "            mean_value = data[column].replace(0, pd.np.nan).mean()\n",
        "            data[column].fillna(mean_value, inplace=True)\n",
        "            data[column] = data[column].replace(0, mean_value)\n",
        "          #  print(\"Column '{}' has been updated. Missing or zero values before: {}. Missing or zero values after: {}. Imputed with value: {}\".format(column, data[column].isna().sum() + (data[column] == 0).sum(), data[column].isna().sum() + (data[column] == 0).sum(), mean_value))\n",
        "\n",
        "# Save the updated data to the original CSV file\n",
        "\n",
        "data[\"diagnosis\"] = (data[\"diagnosis\"] ==\"M\").astype(int)\n",
        "data.to_csv(\"data.csv\", index=False)\n",
        "\n",
        "# Print the updated data\n",
        "print(data[\"diagnosis\"])\n"
      ],
      "metadata": {
        "id": "VnBEJVGnLa8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f313db7-e463-43b8-9cb1-0b970a91c268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "564    1\n",
            "565    1\n",
            "566    1\n",
            "567    1\n",
            "568    0\n",
            "Name: diagnosis, Length: 569, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-4eafaa040278>:20: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
            "  mean_value = data[column].replace(0, pd.np.nan).mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lE_TXS1FEsNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering Task 2:**"
      ],
      "metadata": {
        "id": "JqOvk_qBRTH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the dataset as a Pandas DataFrame\n",
        "df = pd.read_csv('data.csv')\n",
        "# extract the numeric columns except the first two columns and convert to a Numpy array\n",
        "numeric_cols = df.iloc[:, 2:].select_dtypes(include=[np.number]).columns\n",
        "dataset = df[numeric_cols].values\n",
        "\n",
        "# calculate the mean and standard deviation of each feature\n",
        "mu = np.mean(dataset, axis=0)\n",
        "sigma = np.std(dataset, axis=0)\n",
        "\n",
        "# apply feature normalization\n",
        "normalized_dataset = (dataset - mu) / sigma\n",
        "\n",
        "# update the original DataFrame with the normalized values\n",
        "df.loc[:, numeric_cols] = normalized_dataset\n",
        "\n",
        "# save the normalized dataset back to the normData.csv file\n",
        "df.to_csv('normData.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "k67BTzfIHQjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part A - Perceptron Learning Algorithm:**\n"
      ],
      "metadata": {
        "id": "46Z9BDbPRi4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Learning Task 1: ***"
      ],
      "metadata": {
        "id": "Wz8zQ_xFRnW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "data = pd.read_csv('data.csv')\n",
        "data = data.drop('id', axis=1)  # Drop the id column\n",
        "train_data = data.sample(frac=0.67, random_state=1)  # Randomly select 67% of the data for training\n",
        "test_data = data.drop(train_data.index)  # Use the remaining data for testing\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = np.dot(x, self.weights)\n",
        "        return np.where(z > 0, 1, 0)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                y_pred = self.predict(X[i])\n",
        "                error = y[i] - y_pred\n",
        "                self.weights += self.lr * error * X[i]\n",
        "def evaluate(model, test_data):\n",
        "    X_test = test_data.iloc[:, 1:].values\n",
        "    y_test = test_data.iloc[:, 0].values\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    return accuracy\n",
        "\n",
        "pm1 = Perceptron(input_size=train_data.shape[1]-1)\n",
        "pm1.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n",
        "pm1_acc = evaluate(pm1, test_data)\n",
        "print(f\"PM1 accuracy: {pm1_acc}\")\n",
        "\n",
        "pm2 = Perceptron(input_size=train_data.shape[1]-1)\n",
        "train_data = train_data.sample(frac=1)  # Shuffle the training data\n",
        "pm2.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n",
        "pm2_acc = evaluate(pm2, test_data)\n",
        "print(f\"PM2 accuracy: {pm2_acc}\")"
      ],
      "metadata": {
        "id": "aIPdieyyR4DQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9468edff-d69b-47cd-f20b-b7aa9c7ca1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM1 accuracy: 0.9202127659574468\n",
            "PM2 accuracy: 0.925531914893617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have define the perceptron algorithm\n",
        "Then, we have define a function to evaluate the performance of the model on the test set:\n",
        "Now, we can use the perceptron algorithm to train two models (PM1 and PM2) by changing the order of training examples:\n",
        "We can observe that PM1 and PM2 have different accuracies. This is because the order of training examples affects the final weights of the model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GfHmKjkHfJKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Building Perceptron Model PM3 on Normalized Data**"
      ],
      "metadata": {
        "id": "ZQuDaEz83aS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = np.dot(x, self.weights)\n",
        "        return np.where(z > 0, 1, 0)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                y_pred = self.predict(X[i])\n",
        "                error = y[i] - y_pred\n",
        "                self.weights += self.lr * error * X[i]\n",
        "def evaluate(model, test_data):\n",
        "    X_test = test_data.iloc[:, 1:].values\n",
        "    y_test = test_data.iloc[:, 0].values\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    return accuracy\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('normData.csv')\n",
        "data = data.drop('id', axis=1)  # Drop the id column\n",
        "train_data1 = data.sample(frac=0.67, random_state=1)\n",
        "test_data1 = data.drop(train_data.index)\n",
        "\n",
        "# Train PM3 on normalized data\n",
        "pm3 = Perceptron(input_size=train_data1.shape[1]-1)\n",
        "pm3.train(train_data1.iloc[:, 1:].values, train_data1.iloc[:, 0].values)\n",
        "pm3_acc = evaluate(pm3,test_data1)\n",
        "print(f\"PM3 accuracy on normalized data: {pm3_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEh1w_7JiAb4",
        "outputId": "274f88b4-5ba9-45d5-97d0-9d87d9740426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM3 accuracy on normalized data: 0.973404255319149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we trained the PM3 model on the normalized training data and evaluated its performance on the normalized testing data. We can observe that PM3 has a different accuracy than PM1 and PM2 due to the normalized data.\n",
        "\n"
      ],
      "metadata": {
        "id": "rC2rOwAYfjDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: Building Perceptron Model PM4 on Randomly Permutated Features**\n",
        "\n",
        "To build PM4, we will randomly permute the order of features in the dataset:"
      ],
      "metadata": {
        "id": "wk_IePPC3o4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we shuffled the columns (features) of the training data using the sample method and then trained the PM4 model on the shuffled training data. We evaluated its performance on the testing data, but only using the features that have non-zero weights in the PM4 model. This is because the weights of the other features were initialized to zero and remained zero throughout the training process. We can observe that PM4 has a different accuracy than PM1, PM2, and PM3 due to the randomly permuted features."
      ],
      "metadata": {
        "id": "x8wMOhVAfnnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.lr = lr\n",
        "        self.epochs =   epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = np.dot(x, self.weights)\n",
        "        return np.where(z > 0, 1, 0)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                y_pred = self.predict(X[i])\n",
        "                error = y[i] - y_pred\n",
        "                self.weights += self.lr * error * X[i]\n",
        "def evaluate(model, test_data):\n",
        "    X_test = test_data.iloc[:, 1:].values\n",
        "    y_test = test_data.iloc[:, 0].values\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    return accuracy\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Drop id column\n",
        "data = data.drop('id', axis=1)\n",
        "\n",
        "train_data = data.sample(frac=0.67, random_state=1)\n",
        "test_data = data.drop(train_data.index)\n",
        "\n",
        "\n",
        "# Randomly permute feature order\n",
        "np.random.seed(1)\n",
        "perm = np.random.permutation(train_data.shape[1]-1) + 1\n",
        "train_data_permuted = train_data.iloc[:, np.concatenate(([0], perm))]\n",
        "\n",
        "# Train PM4 on permuted data\n",
        "pm4 = Perceptron(input_size=train_data_permuted.shape[1]-1)\n",
        "pm4.train(train_data_permuted.iloc[:, 1:].values, train_data_permuted.iloc[:, 0].values)\n",
        "\n",
        "\n",
        "merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, perm]], axis=1)\n",
        "# num_columns1 = data.shape[1]\n",
        "# num_columns2 = train_data.shape[1]\n",
        "# num_columns3 = test_data.shape[1]\n",
        "\n",
        "# print(\"Number of columns in data :\", num_columns1)\n",
        "# print(\"Number of columns in train data :\", num_columns2)\n",
        "# print(\"Number of columns in test_data :\", num_columns3)\n",
        "\n",
        "# num_columns = merged_test_data.shape[1]\n",
        "\n",
        "#print(\"Number of columns in merged data :\", num_columns)\n",
        "\n",
        "merged_test_data.to_csv('test.csv', index=False)\n",
        "\n",
        "pm4_acc = evaluate(pm4, merged_test_data)\n",
        "print(\"PM4 Accuracy:\", pm4_acc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS5kbZVQnNMx",
        "outputId": "c38845d7-1113-4db8-bdf9-6e2260062860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM4 Accuracy: 0.9202127659574468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy of 10 random samples for PM1**"
      ],
      "metadata": {
        "id": "rZmmmgFKeJli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = np.dot(x, self.weights)\n",
        "        return np.where(z > 0, 1, 0)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                y_pred = self.predict(X[i])\n",
        "                error = y[i] - y_pred\n",
        "                self.weights += self.lr * error * X[i]\n",
        "def evaluate(model, test_data):\n",
        "    X_test = test_data.iloc[:, 1:].values\n",
        "    y_test = test_data.iloc[:, 0].values\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv('data.csv')\n",
        "data = data.drop('id', axis=1)  # Drop the id column\n",
        "\n",
        "\n",
        "\n",
        "accuracies = []\n",
        "for i in range(10):\n",
        "    train_data = data.sample(frac=0.67, random_state=i)  # Randomly select 67% of the data for training\n",
        "    test_data = data.drop(train_data.index)  # Use the remaining data for testing\n",
        "\n",
        "    pm1 = Perceptron(input_size=train_data.shape[1]-1)\n",
        "    pm1.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n",
        "    pm1_acc = evaluate(pm1, test_data)\n",
        "    print(f\"PM1 accuracy: {pm1_acc}\")\n",
        "    accuracies.append(pm1_acc)\n",
        "\n",
        "print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n",
        "print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n"
      ],
      "metadata": {
        "id": "2lCsr01PeN4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ca0d84-cada-4e62-efd3-0e76891743e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM1 accuracy: 0.9202127659574468\n",
            "PM1 accuracy: 0.9202127659574468\n",
            "PM1 accuracy: 0.8776595744680851\n",
            "PM1 accuracy: 0.8563829787234043\n",
            "PM1 accuracy: 0.8351063829787234\n",
            "PM1 accuracy: 0.8882978723404256\n",
            "PM1 accuracy: 0.8776595744680851\n",
            "PM1 accuracy: 0.9202127659574468\n",
            "PM1 accuracy: 0.8829787234042553\n",
            "PM1 accuracy: 0.5638297872340425\n",
            "Mean accuracy: 0.85425532\n",
            "Standard deviation: 0.10042350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy of 10 random samples for PM3**"
      ],
      "metadata": {
        "id": "VegBBuWscgTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = np.dot(x, self.weights)\n",
        "        return np.where(z > 0, 1, 0)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                y_pred = self.predict(X[i])\n",
        "                error = y[i] - y_pred\n",
        "                self.weights += self.lr * error * X[i]\n",
        "def evaluate(model, test_data):\n",
        "    X_test = test_data.iloc[:, 1:].values\n",
        "    y_test = test_data.iloc[:, 0].values\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    return accuracy\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('normData.csv')\n",
        "data = data.drop('id', axis=1)  # Drop the id column\n",
        "accuracies = []\n",
        "for i in range(10):\n",
        "    train_data1 = data.sample(frac=0.67, random_state=i)\n",
        "    test_data1 = data.drop(train_data.index)\n",
        "\n",
        "    # Train PM3 on normalized data\n",
        "    pm3 = Perceptron(input_size=train_data1.shape[1]-1)\n",
        "    pm3.train(train_data1.iloc[:, 1:].values, train_data1.iloc[:, 0].values)\n",
        "    pm3_acc = evaluate(pm3,test_data1)\n",
        "    print(pm3_acc)\n",
        "    accuracies.append(pm3_acc)\n",
        "\n",
        "print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n",
        "print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n"
      ],
      "metadata": {
        "id": "7P4Nler2cfNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6fcd46d-a10f-4ed8-eea3-e95d56e6e8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9414893617021277\n",
            "0.973404255319149\n",
            "0.9521276595744681\n",
            "0.9840425531914894\n",
            "0.9840425531914894\n",
            "0.9680851063829787\n",
            "0.9680851063829787\n",
            "0.9680851063829787\n",
            "0.9521276595744681\n",
            "0.9574468085106383\n",
            "Mean accuracy: 0.96489362\n",
            "Standard deviation: 0.01328723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average accuracy for 10 random samples: PM4**"
      ],
      "metadata": {
        "id": "7Hyc0kHYTMBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Drop id column\n",
        "data = data.drop('id', axis=1)\n",
        "accuracies = []\n",
        "for i in range(10):\n",
        "    # data = data.sample(frac=1)\n",
        "    train_data = data.sample(frac=0.67, random_state=i)\n",
        "    test_data = data.drop(train_data.index)\n",
        "    # split the data into training and testing sets\n",
        "  \n",
        "\n",
        "    # Randomly permute feature order\n",
        "    np.random.seed(1)\n",
        "    perm = np.random.permutation(train_data.shape[1]-1) + 1\n",
        "    train_data_permuted = train_data.iloc[:, np.concatenate(([0], perm))]\n",
        "\n",
        "    # Train PM4 on permuted data\n",
        "    pm4 = Perceptron(input_size=train_data_permuted.shape[1]-1)\n",
        "    pm4.train(train_data_permuted.iloc[:, 1:].values, train_data_permuted.iloc[:, 0].values)\n",
        "\n",
        "\n",
        "    merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, perm]], axis=1)\n",
        "    #merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, np.concatenate(([0], perm))]], axis=1)\n",
        "\n",
        "\n",
        "    pm4_acc = evaluate(pm4, merged_test_data)\n",
        "    print(pm4_acc)\n",
        "    accuracies.append(pm4_acc)\n",
        "\n",
        "print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n",
        "print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bSE-G0ZPTKAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa8145a-b79e-4d84-bead-ce48229fa298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9202127659574468\n",
            "0.9202127659574468\n",
            "0.8776595744680851\n",
            "0.8563829787234043\n",
            "0.8351063829787234\n",
            "0.8882978723404256\n",
            "0.8776595744680851\n",
            "0.9202127659574468\n",
            "0.8829787234042553\n",
            "0.5638297872340425\n",
            "Mean accuracy: 0.85425532\n",
            "Standard deviation: 0.10042350\n"
          ]
        }
      ]
    }
  ]
}